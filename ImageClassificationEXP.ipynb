{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IQ6n_UmmHY4S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1: Load and Preprocess Data\n",
        "# Define transformations for images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),          # Convert images to tensors\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize images\n",
        "])"
      ],
      "metadata": {
        "id": "e0NsWbqvIFIy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Fashion-MNIST dataset\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root=\"./data\", train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "l254MU2HIKb4",
        "outputId": "b0a89b8a-fe88-402b-be2f-92bd5c1efd63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.7MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 165kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.30MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 9.24MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the first image in the training dataset\n",
        "image, label = train_dataset[0]\n",
        "print(image.shape)\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "hio_0YcDKSG6",
        "outputId": "5021e10c-c20e-4632-b184-2c99ca6868e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the first image in the test dataset\n",
        "image, label = test_dataset[0]\n",
        "print(image.shape)\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "id": "Np4cKkebKpmx",
        "outputId": "74c29ad5-0f08-4845-c59f-e1f8c8b02d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader for batch processing\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "6QNx7l2YISUp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        # write your code here\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128 * 3 * 3, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # write your code here\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.relu(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GvzsVmYUIWuo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "1glOMHxdOxlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "# Initialize model\n",
        "model = CNNClassifier()\n",
        "\n",
        "# Move model to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    model.to(device)\n",
        "\n",
        "# Print model summary\n",
        "print('Name: ANU VARSHINI M B')\n",
        "print('Register Number: 212223240010')\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "id": "LHob57oROF77",
        "outputId": "b9c710c5-c45a-43f2-f70e-49205d3198cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: ANU VARSHINI M B\n",
            "Register Number: 212223240010\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "         MaxPool2d-2           [-1, 32, 14, 14]               0\n",
            "            Conv2d-3           [-1, 64, 14, 14]          18,496\n",
            "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
            "            Conv2d-5            [-1, 128, 7, 7]          73,856\n",
            "         MaxPool2d-6            [-1, 128, 3, 3]               0\n",
            "            Linear-7                  [-1, 128]         147,584\n",
            "            Linear-8                   [-1, 64]           8,256\n",
            "            Linear-9                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 249,162\n",
            "Trainable params: 249,162\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.42\n",
            "Params size (MB): 0.95\n",
            "Estimated Total Size (MB): 1.37\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "model =\n",
        "criterion =\n",
        "optimizer ="
      ],
      "metadata": {
        "id": "Zi53JllwIapx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3: Train the Model\n",
        "def train_model(model, train_loader, num_epochs=3):\n",
        "\n",
        "    # write your code here\n",
        "\n",
        "\n",
        "        print('Name:        ')\n",
        "        print('Register Number:       ')\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n"
      ],
      "metadata": {
        "id": "PiziTNVjIjVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_model(model, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFw97_tqInO5",
        "outputId": "12194219-b922-4271-ee58-f4a8a963b39d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.4720\n",
            "Epoch [2/3], Loss: 0.2865\n",
            "Epoch [3/3], Loss: 0.2406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 4: Test the Model\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print('Name:        ')\n",
        "    print('Register Number:       ')\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    print('Name:        ')\n",
        "    print('Register Number:       ')\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_dataset.classes, yticklabels=test_dataset.classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    # Print classification report\n",
        "    print('Name:        ')\n",
        "    print('Register Number:       ')\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=test_dataset.classes))\n"
      ],
      "metadata": {
        "id": "1QrqfMIuIsJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_model(model, test_loader)\n"
      ],
      "metadata": {
        "id": "UobAH8oOIs0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 5: Predict on a Single Image\n",
        "import matplotlib.pyplot as plt\n",
        "def predict_image(model, image_index, dataset):\n",
        "    model.eval()\n",
        "    image, label = dataset[image_index]\n",
        "    with torch.no_grad():\n",
        "        output = model(image.unsqueeze(0))  # Add batch dimension\n",
        "        _, predicted = torch.max(output, 1)\n",
        "    class_names = dataset.classes\n",
        "\n",
        "    # Display the image\n",
        "    print('Name:        ')\n",
        "    print('Register Number:       ')\n",
        "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "    plt.title(f'Actual: {class_names[label]}\\nPredicted: {class_names[predicted.item()]}')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    print(f'Actual: {class_names[label]}, Predicted: {class_names[predicted.item()]}')\n"
      ],
      "metadata": {
        "id": "UXYUZ-V7Iwqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Prediction\n",
        "predict_image(model, image_index=80, dataset=test_dataset)"
      ],
      "metadata": {
        "id": "X9FU-SeUIzmp",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}